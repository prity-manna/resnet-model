{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import keras.utils as ks    \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download and Extract in Google Colab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown 1bcx0UBEaofj4Rj9d6yZm0R7Ycf3-vsQX\n",
    "!tar -xvf \"/content/PlantVillage.tar\" -C \"/content/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract downloaded images file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used while training\n",
    "\n",
    "# import shutil\n",
    "\n",
    "# datafolder = \"PlantVillage/\"\n",
    "# if os.path.exists(datafolder):\n",
    "#     shutil.rmtree(datafolder)\n",
    "# !tar -xf \"emmarex_plantdisease.zip\" -C \"./\" \"PlantVillage/Potato*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modifies the current folder of images with same names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used while training\n",
    "\n",
    "# datafolder = \"./PlantVillage/\"\n",
    "# for folder_name in os.listdir(datafolder):\n",
    "#     count=1\n",
    "#     for file_name in os.listdir(datafolder+folder_name+\"/\"):\n",
    "#         source = datafolder+folder_name+\"/\"+file_name\n",
    "#         destination = datafolder+folder_name+\"/n_\"+str(count)+\".jpg\"\n",
    "#         os.rename(source, destination)\n",
    "#         count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copies the modified images from previous folder to Dataset folder and splitting them into Training, Validation and Testing Sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used while training\n",
    "\n",
    "# import random\n",
    "\n",
    "# def chooseRandomValue(randomInt,dir_len):\n",
    "#     num = random.randint(1,dir_len)\n",
    "#     if num not in randomInt:\n",
    "#         randomInt.append(num)\n",
    "#         return num\n",
    "#     return chooseRandomValue(randomInt,dir_len)\n",
    "\n",
    "# def splitTrainTestValid(src,val,dst,set):\n",
    "#     shutil.copy(src+\"/n_\"+str(val)+\".jpg\",dst+\"n_\"+str(set)+\".jpg\")\n",
    "\n",
    "j=0\n",
    "datafolder = \"./PlantVillage/\"\n",
    "folder = \"./Dataset/\"\n",
    "test = os.path.join(folder,\"Test/\")\n",
    "train = os.path.join(folder,\"Train/\")\n",
    "valid = os.path.join(folder,\"Valid/\")\n",
    "# if os.path.exists(folder):\n",
    "#     shutil.rmtree(folder)\n",
    "\n",
    "# categories = [\"EB\\\\\",\"Healthy\\\\\",\"LB\\\\\"]\n",
    "# for i in categories:\n",
    "#     os.makedirs(test+i)\n",
    "#     os.makedirs(train+i)\n",
    "#     os.makedirs(valid+i)\n",
    "\n",
    "# train_size = 0.8\n",
    "# valid_size = 0.1\n",
    "\n",
    "# for folder_name in os.listdir(datafolder):\n",
    "#     randomInt = []\n",
    "#     dir_len = len(os.listdir(datafolder+folder_name))\n",
    "#     for i in range(1,dir_len+1):\n",
    "#         num = chooseRandomValue(randomInt,dir_len)\n",
    "#         if i<=round(train_size*dir_len):\n",
    "#             splitTrainTestValid(datafolder+folder_name,num,train+str(categories[j]),i)\n",
    "#         elif i<=round((train_size+valid_size)*dir_len) and i>round(train_size*dir_len):\n",
    "#             splitTrainTestValid(datafolder+folder_name,num,valid+str(categories[j]),i)\n",
    "#         elif i<=dir_len and i>round((train_size+valid_size)*dir_len):\n",
    "#             splitTrainTestValid(datafolder+folder_name,num,test+str(categories[j]),i)\n",
    "#     j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define training, validation and testing datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = \"inferred\"\n",
    "label_mode = \"categorical\"\n",
    "batch_size = 16\n",
    "image_size = (256,256)\n",
    "\n",
    "train_ds = ks.image_dataset_from_directory(\n",
    "    train,\n",
    "    image_size=image_size,\n",
    "    labels=labels,\n",
    "    label_mode=label_mode,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "valid_ds = ks.image_dataset_from_directory(\n",
    "    valid,\n",
    "    labels=labels,\n",
    "    label_mode=label_mode,\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    ")\n",
    "test_ds = ks.image_dataset_from_directory(\n",
    "    test,\n",
    "    labels=labels,\n",
    "    label_mode=label_mode,\n",
    "    batch_size=batch_size//batch_size,\n",
    "    image_size=image_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display random images from training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1): \n",
    "    for i in range(16):\n",
    "        ax = plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ResNet50 Identity Block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, filter):\n",
    "    X_skip = X\n",
    "    #Layer 1\n",
    "    X = Conv2D(\n",
    "        filters=filter[0],\n",
    "        kernel_size=1,\n",
    "        padding='same')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    #Layer 2\n",
    "    X = Conv2D(\n",
    "        filters=filter[1],\n",
    "        kernel_size=3,\n",
    "        padding='same')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    #Layer 3\n",
    "    X = Conv2D(\n",
    "        filters=filter[2],\n",
    "        kernel_size=1,\n",
    "        padding='same')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    # SKIP CONNECTION\n",
    "    X = Add()([X, X_skip])\n",
    "    X = Activation('relu')(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ResNet50 Convolutional Block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, filter):\n",
    "    X_skip = X\n",
    "    #Layer 1\n",
    "    X = Conv2D(\n",
    "        filters=filter[0],\n",
    "        kernel_size=1,\n",
    "        strides=2,\n",
    "        padding='same')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    #Layer 2\n",
    "    X = Conv2D(\n",
    "        filters=filter[1],\n",
    "        kernel_size=3,\n",
    "        padding='same')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    #Layer 3\n",
    "    X = Conv2D(\n",
    "        filters=filter[2],\n",
    "        kernel_size=1,\n",
    "        padding='same')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    #Layer 4\n",
    "    X_skip = Conv2D(\n",
    "        filters=filter[2],\n",
    "        kernel_size=1,\n",
    "        strides=2,\n",
    "        padding='same')(X_skip)\n",
    "    X_skip = BatchNormalization(axis=3)(X_skip)\n",
    "    #SKIP CONNECTION\n",
    "    X = Add()([X, X_skip])\n",
    "    X = Activation('relu')(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ResNet50 model block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape):\n",
    "    X_input = X = Input(input_shape)\n",
    "    X = ZeroPadding2D(padding=3)(X)\n",
    "    #Layer 1\n",
    "    X = Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=7,\n",
    "        strides=2,\n",
    "        padding='valid')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(\n",
    "        pool_size=3,\n",
    "        strides=2,\n",
    "        padding='same')(X)\n",
    "    #Layer 2\n",
    "    X = convolutional_block(X, [64, 64, 256])\n",
    "    X = identity_block(X, [64, 64, 256])\n",
    "    X = identity_block(X, [64, 64, 256])\n",
    "    #Layer 3\n",
    "    X = convolutional_block(X, [128, 128, 512])\n",
    "    X = identity_block(X, [128, 128, 512])\n",
    "    X = identity_block(X, [128, 128, 512])\n",
    "    X = identity_block(X, [128, 128, 512])\n",
    "    #Layer 4\n",
    "    X = convolutional_block(X, [256, 256, 1024])\n",
    "    X = identity_block(X, [256, 256, 1024])\n",
    "    X = identity_block(X, [256, 256, 1024])\n",
    "    X = identity_block(X, [256, 256, 1024])\n",
    "    X = identity_block(X, [256, 256, 1024])\n",
    "    X = identity_block(X, [256, 256, 1024])\n",
    "    #Layer 5\n",
    "    X = convolutional_block(X, [512, 512, 2048])\n",
    "    X = identity_block(X, [512, 512, 2048])\n",
    "    X = identity_block(X, [512, 512, 2048])\n",
    "    X = AveragePooling2D(\n",
    "        pool_size=2,\n",
    "        padding='same')(X)\n",
    "    model = Model(\n",
    "        inputs=X_input,\n",
    "        outputs=X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(image_size + (3,))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = base_model.output\n",
    "headModel = Flatten()(headModel)\n",
    "headModel = Dense(1024, activation='relu')(headModel)\n",
    "headModel = Dense(512, activation='relu')(headModel)\n",
    "headModel = Dense(256, activation='relu')(headModel)\n",
    "headModel = Dense(128, activation='relu')(headModel)\n",
    "headModel = Dense(3, activation='softmax')(headModel)\n",
    "model = Model(inputs=base_model.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Brief Summary of the implemented model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used while training\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting of the above implemented model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used while training\n",
    "\n",
    "# from keras.utils import plot_model\n",
    "\n",
    "# plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Already compiled and trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(0.001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Training only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used while training\n",
    "\n",
    "# epoch = 200\n",
    "\n",
    "# mc = ModelCheckpoint(\n",
    "#     f'./final_model.h5',\n",
    "#     monitor='val_accuracy',\n",
    "#     save_best_only=True,\n",
    "#     verbose=1,\n",
    "#     mode='max'\n",
    "# )\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     epochs=epoch,\n",
    "#     validation_data=valid_ds,\n",
    "#     callbacks=[mc]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Testing unseen data only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display Accuracy Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "epochs_range= range(epoch)\n",
    "\n",
    "plt.plot(epochs_range, history.history['accuracy'], label=\"Training Accuracy\")\n",
    "\n",
    "plt.plot(epochs_range, history.history['val_accuracy'], label=\"Validation Accuracy\")\n",
    "\n",
    "plt.axis(ymin=0.4,ymax=1)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "\n",
    "plt.legend(['train', 'validation'])\n",
    "\n",
    "plt.savefig('output-plot.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display Loss Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "epochs_range= range(epoch)\n",
    "\n",
    "plt.plot( epochs_range, history.history['loss'], label=\"Training Loss\")\n",
    "\n",
    "plt.plot(epochs_range, history.history['val_loss'], label=\"Validation Loss\")\n",
    "\n",
    "plt.axis(ymin=0.0,ymax=1.0)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.title('Model Loss')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "\n",
    "plt.legend(['train', 'validation'])\n",
    "\n",
    "plt.savefig('output-plot-loss.png')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3057bd7bac9b91172ce66ca8fca532e54a1c9193cd308d01dfe16862e9ed6477"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
